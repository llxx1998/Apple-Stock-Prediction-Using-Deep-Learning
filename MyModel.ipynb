{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Overview\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this project is for you to demonstrate your mastery of the Machine Learning process\n",
    "**using Neural Networks**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission requirements\n",
    "\n",
    "The guidelines will be similar to the Midterm\n",
    "- you will write a procedure that takes raw data and produces predictions\n",
    "\n",
    "You will submit a *single* model for evaluation.\n",
    "\n",
    "**Demonstrate that all cells in your notebook work**\n",
    "\n",
    "The final cell in your notebook should print the message \"Done\"\n",
    "- `print(\"Done\")`\n",
    "- If we run your notebook and this last cell does not execute your submission will be inadequate\n",
    "\n",
    "## Testing\n",
    "\n",
    "*You must perform out of sample testing*.\n",
    "\n",
    "If you want to perform cross-validation in training, that is fine, but you\n",
    "must *also* test out of sample to show that you are not over-fitting.\n",
    "\n",
    "It is up to you to create the out of sample data that you feel best evaluates your model.\n",
    "\n",
    "We will create holdout data (that we will not show you) for grading.\n",
    "\n",
    "The procedure you write to make predictions should be able to work on the unseen holdout data\n",
    "(similar to how it should work for your test set but the holdout set has *no targets*)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "Data will be provided to you \n",
    "- as multiple files in a directory which we refer to as a *data directory*\n",
    "\n",
    "The reason for this is that the different files may convey different information.\n",
    "\n",
    "You will be responsible for deciding\n",
    "- which files to use\n",
    "- which fields within the files to use\n",
    "\n",
    "We will give you a data directory for training.\n",
    "\n",
    "# Submission guidelines\n",
    "\n",
    "Here are the basics, a code template that you must complete is in the following cells\n",
    "- you will be required to store  your model in a file\n",
    "- you will be required to write a procedure `MyModel` that takes two arguments\n",
    "    - `test_dir`\n",
    "        - this is a *relative path* to the holdout data directory\n",
    "    - `model_path`\n",
    "        - this is a *relative path* to the file containing your model\n",
    "- the holdout data directory is similar in structure to the training data directory\n",
    "    - but without target labels !  It is your job to predict these.\n",
    "- your procedure must produce predictions given this holdout data directory\n",
    "\n",
    "This means that your procedure must\n",
    "- prepare the files in the holdout data directory similar to the way that they were prepared in the training data directory\n",
    "\n",
    "We will provide you with a sample data directory that will resemble the holdout -- this is so that you\n",
    "may test the procedure you write for submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed submission guidelines\n",
    "\n",
    "\n",
    "In **addition to your notebook that trains/evaluates your model**, \n",
    "- please also submit an **archive file of the directory** whose name is stored in `model_path`, which \n",
    "contains your trained model.\n",
    "    - use `saveModel` to put your final, trained model in this directory\n",
    "- We will **not** train your model; we will only use the method `MyModel`\n",
    "    - which **you** will implement\n",
    "    - and which uses `loadModel` and the directory whose name is stored in `model_path`\n",
    "    - this will create the model that we will evaluate\n",
    "\n",
    "\n",
    "Here is a code template for you to complete\n",
    "- it will save your model (assuming it is in variable `my_model`)\n",
    "- it provides the specification for procedure `MyModel`, which *you must complete*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./final_model already exists, files will be over-written.\n",
      "Model saved in directory ./final_model; create an archive of this directory and submit with your assignment.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "modelName = \"final_model\"\n",
    "model_path = os.path.join(\".\", modelName)\n",
    "\n",
    "def flatten3D(mat3D):\n",
    "    ori_shape = mat3D.shape\n",
    "    mat2D = mat3D.reshape((ori_shape[0], ori_shape[1] * ori_shape[2]))\n",
    "    return mat2D\n",
    "\n",
    "class Winsor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_new = pd.DataFrame(np.array(X).copy())\n",
    "        self.High = []\n",
    "        self.Low = []\n",
    "        for col in X_new.columns:\n",
    "            self.High.append(X_new[col].quantile(0.9))\n",
    "            self.Low.append(X_new[col].quantile(0.1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = pd.DataFrame(np.array(X).copy())\n",
    "        for i, col in enumerate(X_new.columns):\n",
    "            high = self.High[i]\n",
    "            low = self.Low[i]\n",
    "            X_new.loc[X_new[col] > high, col] = high\n",
    "            X_new.loc[X_new[col] < low, col] = low\n",
    "        return X_new.values\n",
    "\n",
    "def GenerateTest(dir, lag = 90, var_ls=['Close', 'Volume']):\n",
    "    comp_list = ['CSCO', 'ADBE', 'XLE', 'INTC', 'XLF', \n",
    "                 'XLP', 'MSFT', 'XLB', 'XLU', 'NVDA', \n",
    "                 'XLV', 'IBM', 'XLY', 'XLK', 'SPY', 'XLI', 'AAPL']\n",
    "    data = easyAccess.lsGetCompData(var_ls=var_ls, comp_ls=comp_list, data_path=dir).pct_change()\n",
    "    data.columns = ['pct ' + x for x in data.columns]\n",
    "    X = []\n",
    "    for col in data.columns:\n",
    "        temp = data[[col]].copy()\n",
    "        for i in range(1, lag+1):\n",
    "            temp[str(i) + col] = temp[col].shift(i)\n",
    "        temp.dropna(inplace=True)\n",
    "        X.append(temp.values)\n",
    "    X = np.array(X)\n",
    "    X = np.swapaxes(X, 0, 1)\n",
    "    X = np.swapaxes(X, 1, 2)\n",
    "    ## spatial in time order\n",
    "    X = X[:, ::-1, :]\n",
    "    idx = data.iloc[- X.shape[0]:, ].index\n",
    "    print(X.shape, idx.shape)\n",
    "    return X, idx\n",
    "\n",
    "class easyAccess:\n",
    "    def __init__(self, data_path='./Data/train'):\n",
    "        self.data_path = data_path\n",
    "        self.file_names = os.listdir(data_path)\n",
    "        self.comp_names = [x.split('.')[0] for x in self.file_names]\n",
    "        self.file_dict = dict(zip(self.comp_names, self.file_names))\n",
    "    \n",
    "    @classmethod\n",
    "    def printAll(cls, data_path='./Data/train', mute=True):\n",
    "        obj = cls(data_path)\n",
    "        if not mute:\n",
    "            for i, comp in enumerate(obj.comp_names):\n",
    "                print(i+1, comp)\n",
    "        return obj.comp_names\n",
    "    \n",
    "    @classmethod\n",
    "    def printDetail(cls, data_path='./Data/train'):\n",
    "        obj = cls(data_path)\n",
    "        for key, value in obj.file_dict.items():\n",
    "            print(key, end=':\\t')\n",
    "            df = pd.read_csv(os.path.join(obj.data_path, value))\n",
    "            print(\", \".join(list(df.columns)))\n",
    "    \n",
    "    @classmethod\n",
    "    def lsGetData(cls, var_ls=None, data_path='./Data/train'):\n",
    "        \"\"\"\n",
    "        Get data by transferring in a variable-name list and fetch data for all the companies. \n",
    "        \"\"\"\n",
    "        if not var_ls or var_ls == []:\n",
    "            return None\n",
    "        obj = cls(data_path)\n",
    "        result = None\n",
    "        for key, value in obj.file_dict.items():\n",
    "            df = pd.read_csv(os.path.join(obj.data_path, value))\n",
    "            df['Dt'] = pd.to_datetime(df['Dt'], format='%Y-%m-%d')\n",
    "            df.set_index('Dt', inplace=True)\n",
    "            df = df[var_ls]\n",
    "            df.columns = [' '.join([key, x]) for x in df.columns]\n",
    "            if result is None:\n",
    "                result = df\n",
    "            else:\n",
    "                result = result.merge(df, how='outer', left_index=True, right_index=True)\n",
    "        print('Data acquisition completed!', \", \".join(var_ls))\n",
    "        return result\n",
    "                \n",
    "    @classmethod\n",
    "    def lsGetCompData(cls, var_ls=None, comp_ls=None, data_path='./Data/train'):\n",
    "        \"\"\"\n",
    "        Get data by transferring in a variable-name list and fetch data for all the companies. \n",
    "        \"\"\"\n",
    "        if not var_ls or var_ls == []:\n",
    "            return None\n",
    "        obj = cls(data_path)\n",
    "        result = None\n",
    "        for key in comp_ls:\n",
    "            value = obj.file_dict[key]\n",
    "            df = pd.read_csv(os.path.join(obj.data_path, value))\n",
    "            df['Dt'] = pd.to_datetime(df['Dt'], format='%Y-%m-%d')\n",
    "            df.set_index('Dt', inplace=True)\n",
    "            df = df[var_ls]\n",
    "            df.columns = [' '.join([key, x]) for x in df.columns]\n",
    "            if result is None:\n",
    "                result = df\n",
    "            else:\n",
    "                result = result.merge(df, how='outer', left_index=True, right_index=True)\n",
    "        print('Data acquisition completed!', \", \".join(var_ls))\n",
    "        return result\n",
    "        \n",
    "\n",
    "def saveModel(model, model_path): \n",
    "    try:\n",
    "        os.makedirs(model_path)\n",
    "    except OSError:\n",
    "        print(\"Directory {dir:s} already exists, files will be over-written.\".format(dir=model_path))\n",
    "        \n",
    "    # Save JSON config to disk\n",
    "    json_config = model.to_json()\n",
    "    with open(os.path.join(model_path, 'config.json'), 'w') as json_file:\n",
    "        json_file.write(json_config)\n",
    "    # Save weights to disk\n",
    "    model.save_weights(os.path.join(model_path, 'weights.h5'))\n",
    "    \n",
    "    print(\"Model saved in directory {dir:s}; create an archive of this directory and submit with your assignment.\".format(dir=model_path))\n",
    "    \n",
    "def loadModel(model_path):\n",
    "    # Reload the model from the 2 files we saved\n",
    "    with open(os.path.join(model_path, 'config.json')) as json_file:\n",
    "        json_config = json_file.read()\n",
    "    model = tf.keras.models.model_from_json(json_config)\n",
    "    model.load_weights(os.path.join(model_path, 'weights.h5'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def MyModel(test_dir, model_path):\n",
    "    # YOU MAY NOT change model after this statement !\n",
    "    model = loadModel(model_path)\n",
    "\n",
    "    # It should run model to create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # We need to match your array of predictions with the examples you are predicting\n",
    "    # The array below (ids) should have a one-to-one correspondence and identify the example your are predicting\n",
    "    # For Bankruptcy: the Id column\n",
    "    # For Stock prediction: the date on which you are making a prediction\n",
    "    ids = []\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    X_raw, idx = GenerateTest(dir=test_dir, lag = 90, var_ls = ['Close', 'Volume'])\n",
    "\n",
    "    # load autoencoder model\n",
    "    with open(os.path.join('.', 'final_preprocess', 'final_model_autoencoder.pkl'), 'rb') as f:\n",
    "        ae_recovered = pickle.load(f)\n",
    "    # load model pipeline\n",
    "    with open(os.path.join('.', 'final_preprocess', 'final_model_pipeline.pkl'), 'rb') as f:\n",
    "        pipe_recovered = pickle.load(f)\n",
    "    # load model raw function\n",
    "    with open(os.path.join('.', 'final_preprocess', 'final_model_raw_func.pkl'), 'rb') as f:\n",
    "        func_recovered = pickle.load(f)\n",
    "    \n",
    "    print(ae_recovered, pipe_recovered, func_recovered)\n",
    "\n",
    "    shape_test = X_raw.shape\n",
    "    X_raw = pipe_recovered.transform(func_recovered(X_raw))\n",
    "    X_raw = X_raw.reshape(shape_test)\n",
    "    X_raw = ae_recovered.predict(X_raw)\n",
    "    X_raw.shape\n",
    "    print(X_raw.shape)\n",
    "\n",
    "    model_f = loadModel(model_path)\n",
    "    y_pred = model_f.predict(X_raw)\n",
    "    \n",
    "    predictions = y_pred[-200:].reshape([-1])\n",
    "    ids = np.array(idx)[-200:]\n",
    "\n",
    "    return predictions, ids\n",
    "\n",
    "# Assign to variable my_model the model that is your final model (the one  you will be evaluated on)\n",
    "model_11 = loadModel(model_path)\n",
    "my_model = model_11 # CHANGE None to your model !\n",
    "\n",
    "saveModel(my_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model on the holdout data directory\n",
    "\n",
    "**You must run the following cell** from the directory that contains your model file\n",
    "\n",
    "Here is how we will evaluate your submission\n",
    "- we will create a directory whose only content is\n",
    "    - sub-directory `Data`\n",
    "- we will copy your model file to this directory with the name stored in `model_path`\n",
    "- we will run the cell in your notebook that should be a copy of the one below\n",
    "    - it calls procedure `MyModel` with the arguments given below\n",
    "    - your implementation of `MyModel`\n",
    "        - must successfully load your model file, *given where **we** have place it as described above*\n",
    "        - must successfully return one prediction for each example in the holdout directory *given where **we** have placed the holdout directory*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "When grading, please change the holdout_dir to holdout dataset. Currently, it's under testing using sample data. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data acquisition completed! Close, Volume\n",
      "(160, 91, 34) (160,)\n",
      "<keras.engine.sequential.Sequential object at 0x7f7afe93f190> Pipeline(steps=[('Winsor', Winsor()), ('Scaler', StandardScaler())]) <function flatten3D at 0x7f7b010b17a0>\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7b00831710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7b00831710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(160, 91, 34)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7b02593050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7b02593050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "holdout_dir = os.path.join(\".\", \"Data\", \"sample\")\n",
    "predicts = MyModel(holdout_dir, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
